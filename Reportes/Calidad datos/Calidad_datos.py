# ================================================================
# Script: calidad_datos.py
# Autor: Karen Juliana Su√°rez Cruz
# Descripci√≥n: 
#   Este script realiza un proceso completo de calidad y depuraci√≥n 
#   sobre la base de datos de la Fuerza A√©rea Colombiana (FAC).
#   Incluye:
#   - Carga de datos
#   - An√°lisis exploratorio inicial
#   - Identificaci√≥n de faltantes, duplicados y encoding defectuoso
#   - Normalizaci√≥n y estandarizaci√≥n de texto
#   - Imputaci√≥n l√≥gica en variables familiares
#   - Exportaci√≥n de dataset corregido
# ================================================================

# ================== 0. IMPORTACI√ìN DE LIBRER√çAS ==================
import pandas as pd
import numpy as np
import unicodedata
import re

from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.experimental import enable_iterative_imputer  # habilita IterativeImputer
from sklearn.impute import IterativeImputer, KNNImputer

# ================== 1. CARGA DE DATOS ==================
# Se lee la base de datos desde Excel
df = pd.read_excel('datos/JEFAB_2024.xlsx')

# Se imprime informaci√≥n b√°sica del dataset
print(f"\n=== INFORMACI√ìN GENERAL ===")
print(f"Filas: {df.shape[0]} | Columnas: {df.shape[1]}")

# ================== 2. AN√ÅLISIS INICIAL ==================
# ---- Datos faltantes ----
print("=== AN√ÅLISIS DE DATOS FALTANTES ===")
missing_data = df.isnull().sum()                    # Conteo de valores nulos
missing_percent = (missing_data / len(df)) * 100    # Porcentaje de nulos
missing_info = pd.DataFrame({                       # DataFrame resumen
    'Columna': missing_data.index,
    'Datos_Faltantes': missing_data.values,
    'Porcentaje': missing_percent.values
}).sort_values('Datos_Faltantes', ascending=False)
print("Top 10 columnas con m√°s datos faltantes:")
print(missing_info.head(10))

# ---- Registros duplicados ----
print(f"\n=== AN√ÅLISIS DE DUPLICADOS ===")
print(f"Registros duplicados: {df.duplicated().sum()}")

# ---- Tipos de datos ----
print(f"\n=== TIPOS DE DATOS ===")
print(df.dtypes.value_counts())

# ---- Problemas de encoding en nombres de columnas ----
print(f"\n=== COLUMNAS CON CARACTERES ESPECIALES ===")
problematic_columns = [col for col in df.columns if '√É' in col or '√¢' in col]
print(f"Columnas con encoding problem√°tico: {len(problematic_columns)}")
for col in problematic_columns[:5]:   # Se listan solo las primeras 5
    print(f" - {col}")

# ================== 3. FUNCIONES DE LIMPIEZA ==================
# Diccionario de reemplazos para corregir errores comunes de codificaci√≥n
reemplazos = {
    "√É¬°": "√°", "√É¬©": "√©", "√É¬≠": "√≠", "√É¬≥": "√≥", "√É¬∫": "√∫",
    "√É¬Å": "√Å", "√É‚Ä∞": "√â", "√É¬ç": "√ç", "√É‚Äú": "√ì", "√É≈°": "√ö",
    "√É¬±": "√±", "√É‚Äò": "√ë", "√É¬º": "√º", "√É≈ì": "√ú"
}

def corregir_encoding(s: str) -> str:
    """Corrige caracteres mal codificados en un string."""
    if not isinstance(s, str):   # Si no es texto, lo deja igual
        return s
    for k, v in reemplazos.items():
        s = s.replace(k, v)
    return s

def normalizar_texto(s):
    """Normaliza texto: corrige encoding, elimina acentos y pasa a min√∫sculas."""
    if pd.isna(s):
        return s
    s = str(s)
    s = corregir_encoding(s)
    # Se eliminan acentos con unicodedata
    s = ''.join(c for c in unicodedata.normalize('NFKD', s) 
                if not unicodedata.combining(c))
    return s.strip().lower()

# Diccionario de categor√≠as equivalentes (singulares, plurales, variantes con acento)
map_categorias = {
    "Madre": ["mama", "mam√°", "madre"],
    "Padre": ["papa", "pap√°", "padre"],
    "Tio": ["tio", "t√≠o"],
    "Tia": ["tia", "t√≠a"],
    "Primo": ["primo"],
    "Prima": ["prima"],
    "Abuelo": ["abuelo"],
    "Abuela": ["abuela"],
    "Madres": ["mamas", "mam√°s", "madres"],
    "Padres": ["papas", "pap√°s", "padres"],
    "Tios": ["tios", "t√≠os"],
    "Tias": ["tias", "t√≠as"],
    "Primos": ["primos"],
    "Primas": ["primas"],
    "Abuelos": ["abuelos"],
    "Abuelas": ["abuelas"]
}

# Invertir el diccionario: de variante -> categor√≠a can√≥nica
canon_map = {}
for canon, variantes in map_categorias.items():
    for v in variantes:
        canon_map[normalizar_texto(v)] = canon

# ================== 4. AGRUPAMIENTO DE VARIANTES ==================
# Se agrupan valores equivalentes en columnas de texto
text_cols = df.select_dtypes(include=['object']).columns
agrupamientos = {}
for col in text_cols:
    valores = df[col].dropna().astype(str).unique()
    agrupados = {}
    for val in valores:
        norm = normalizar_texto(val)
        canon = canon_map.get(norm, val)   # Si existe, lo reemplaza por su categor√≠a
        agrupados.setdefault(canon, []).append(val)
    # Solo se reportan agrupamientos con m√°s de una variante
    agrupamientos[col] = {k: v for k, v in agrupados.items() if len(v) > 1}

# Reporte de agrupamientos detectados
print("\n=== AGRUPAMIENTO DE VARIANTES (Singular/Plural/G√©nero) ===")
for col, grupos in agrupamientos.items():
    if grupos:
        print(f"\nColumna: {col}")
        for canon, variantes in grupos.items():
            print(f"  ‚Üí {canon}: {variantes}")

# ================== 5. CREAR DATASET CORREGIDO ==================
df_corregido = df.copy()

for col in text_cols:
    # Normalizaci√≥n b√°sica
    df_corregido[col] = df_corregido[col].astype(str).apply(lambda x: normalizar_texto(x) if x != 'nan' else np.nan)
    # Limpieza de separadores en listas (ej: "madre ; padre")
    df_corregido[col] = df_corregido[col].str.replace(r'\s*;\s*', ';', regex=True)
    # Reemplazo por categor√≠as can√≥nicas
    df_corregido[col] = df_corregido[col].apply(
        lambda x: canon_map.get(x, x) if isinstance(x, str) else x
    )

# ================== 6. DEPURACI√ìN CON IMPUTACI√ìN L√ìGICA ==================
# --- Relaci√≥n HIJOS vs NUMERO_HIJOS ---
if 'HIJOS' in df_corregido.columns and 'NUMERO_HIJOS' in df_corregido.columns:
    cambios = ((df_corregido['HIJOS'] == "no") & (df_corregido['NUMERO_HIJOS'].isna())).sum()
    print(f"\n=== IMPUTACI√ìN L√ìGICA: HIJOS vs NUMERO_HIJOS ===")
    print(f"Registros a corregir: {cambios}")
    # Se imputan 0 hijos cuando la persona dijo expl√≠citamente que no tiene
    df_corregido.loc[
        (df_corregido['HIJOS'] == "no") & (df_corregido['NUMERO_HIJOS'].isna()), 
        'NUMERO_HIJOS'
    ] = 0
    print(f"Correcci√≥n aplicada.")

# --- Relaci√≥n HIJOS vs HIJOS_EN_HOGAR ---
if 'HIJOS' in df_corregido.columns and 'HIJOS_EN_HOGAR' in df_corregido.columns:
    cambios = ((df_corregido['HIJOS'] == "no") & (df_corregido['HIJOS_EN_HOGAR'].isna())).sum()
    print(f"\n=== IMPUTACI√ìN L√ìGICA: HIJOS vs HIJOS_EN_HOGAR ===")
    print(f"Registros a corregir: {cambios}")
    df_corregido.loc[
        (df_corregido['HIJOS'] == "no") & (df_corregido['HIJOS_EN_HOGAR'].isna()), 
        'HIJOS_EN_HOGAR'
    ] = 0
    print("Correcci√≥n aplicada.")

# --- Relaci√≥n MADRE_VIVE vs EDAD_MADRE ---
if 'MADRE_VIVE' in df_corregido.columns:
    cambios_madre = ((df_corregido['MADRE_VIVE'] == "no") & (df_corregido['EDAD_MADRE'].isna())).sum()
    df_corregido.loc[(df_corregido['MADRE_VIVE'] == "no") & (df_corregido['EDAD_MADRE'].isna()), 'EDAD_MADRE'] = 0
    print(f"\n=== IMPUTACI√ìN L√ìGICA: MADRE_VIVE vs EDAD_MADRE ===")
    print(f"Registros corregidos: {cambios_madre}")

    cambios_rango_madre = ((df_corregido['MADRE_VIVE'] == "no") & (df_corregido['EDAD_RANGO_MADRE'].isna())).sum()
    df_corregido.loc[(df_corregido['MADRE_VIVE'] == "no") & (df_corregido['EDAD_RANGO_MADRE'].isna()), 'EDAD_RANGO_MADRE'] = 0
    print(f"Registros corregidos en rango madre: {cambios_rango_madre}")

# --- Relaci√≥n PADRE_VIVE vs EDAD_PADRE ---
if 'PADRE_VIVE' in df_corregido.columns:
    cambios_padre = ((df_corregido['PADRE_VIVE'] == "no") & (df_corregido['EDAD_PADRE'].isna())).sum()
    df_corregido.loc[(df_corregido['PADRE_VIVE'] == "no") & (df_corregido['EDAD_PADRE'].isna()), 'EDAD_PADRE'] = 0
    print(f"\n=== IMPUTACI√ìN L√ìGICA: PADRE_VIVE vs EDAD_PADRE ===")
    print(f"Registros corregidos: {cambios_padre}")

    cambios_rango_padre = ((df_corregido['PADRE_VIVE'] == "no") & (df_corregido['EDAD_RANGO_PADRE'].isna())).sum()
    df_corregido.loc[(df_corregido['PADRE_VIVE'] == "no") & (df_corregido['EDAD_RANGO_PADRE'].isna()), 'EDAD_RANGO_PADRE'] = 0
    print(f"Registros corregidos en rango padre: {cambios_rango_padre}")

# ============================================================
# PASO 7: Imputaci√≥n avanzada de variables
# ============================================================

from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer
import matplotlib.pyplot as plt

# --- 7A. Preparamos columnas num√©ricas ---
num_cols = df_corregido.select_dtypes(include=["int64", "float64"]).columns
df_temp = df_corregido[num_cols].copy()

# --- 7B. Convertir ceros en NaN SOLO si el padre/madre est√° vivo ---
mask_padre_vivo = df_corregido["PADRE_VIVE"] == 1
mask_madre_vivo = df_corregido["MADRE_VIVE"] == 1

for col in ["EDAD_PADRE", "EDAD_RANGO_PADRE"]:
    if col in df_temp.columns:
        df_temp.loc[mask_padre_vivo & (df_temp[col] == 0), col] = np.nan

for col in ["EDAD_MADRE", "EDAD_RANGO_MADRE"]:
    if col in df_temp.columns:
        df_temp.loc[mask_madre_vivo & (df_temp[col] == 0), col] = np.nan

# --- 7C. Aplicamos MICE ---
imputer = IterativeImputer(max_iter=10, random_state=42)
df_imputado = imputer.fit_transform(df_temp)

# Convertimos a DataFrame para mantener nombres y control
df_imputado = pd.DataFrame(df_imputado, columns=num_cols, index=df_temp.index)

# --- üö® 7Cbis: Evitar negativos en TODAS las columnas num√©ricas ---
df_imputado = df_imputado.clip(lower=0)

# Redondear a enteros
df_imputado = np.round(df_imputado).astype(int)

# Reemplazamos en la base corregida
df_corregido[num_cols] = df_imputado

# --- 7D. Restaurar ceros para padres/madres fallecidos ---
df_corregido.loc[df_corregido["PADRE_VIVE"] == 0, ["EDAD_PADRE", "EDAD_RANGO_PADRE"]] = 0
df_corregido.loc[df_corregido["MADRE_VIVE"] == 0, ["EDAD_MADRE", "EDAD_RANGO_MADRE"]] = 0

print("\n>>> Imputaci√≥n MICE aplicada en todas las variables num√©ricas. Negativos truncados a 0. Cerros preservados en fallecidos.")

# --- 7E. Reconstrucci√≥n de rangos despu√©s de imputaci√≥n con MICE ---
# --- Funci√≥n para asignar rangos ---
def edad_a_rango(edad):
    if pd.isna(edad) or edad == 0:
        return 0   # fallecido o sin dato
    elif 18 <= edad <= 22:
        return "18-22"
    elif 23 <= edad <= 27:
        return "23-27"
    elif 28 <= edad <= 32:
        return "28-32"
    elif 33 <= edad <= 37:
        return "33-37"
    elif 38 <= edad <= 42:
        return "38-42"
    elif 43 <= edad <= 47:
        return "43-47"
    elif 48 <= edad <= 52:
        return "48-52"
    elif 53 <= edad <= 57:
        return "53-57"
    elif 58 <= edad <= 62:
        return "58-62"
    else:
        return "Otro"

# --- Asignar rangos para madres vivas ---
df_corregido.loc[df_corregido["MADRE_VIVE"] == 1, "EDAD_RANGO_MADRE"] = (
    df_corregido.loc[df_corregido["MADRE_VIVE"] == 1, "EDAD_MADRE"].apply(edad_a_rango)
)

# --- Asignar rangos para padres vivos ---
df_corregido.loc[df_corregido["PADRE_VIVE"] == 1, "EDAD_RANGO_PADRE"] = (
    df_corregido.loc[df_corregido["PADRE_VIVE"] == 1, "EDAD_PADRE"].apply(edad_a_rango)
)

# --- Asegurar ceros en fallecidos ---
df_corregido.loc[df_corregido["MADRE_VIVE"] == 0, ["EDAD_MADRE","EDAD_RANGO_MADRE"]] = 0
df_corregido.loc[df_corregido["PADRE_VIVE"] == 0, ["EDAD_PADRE","EDAD_RANGO_PADRE"]] = 0



print("\n>>> Reconstrucci√≥n de rangos de edad realizada correctamente.")


#  ================== 8. GUARDAR RESULTADO ==================
df_corregido.to_excel("datos/JEFAB_2024_corregido.xlsx", index=False)
print("\n>>> Dataset corregido guardado como 'datos/JEFAB_2024_corregido.xlsx'")
